{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import os \n",
    "import sys\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "import scipy.stats as st\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Make Data Directory\n",
    "!mkdir Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Download Yellow Taxi Data\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-01.csv    \n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-02.csv    \n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-03.csv    \n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-04.csv    \n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-05.csv    \n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-06.csv    \n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-07.csv    \n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-08.csv    \n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-09.csv    \n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-10.csv    \n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-11.csv    \n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-12.csv    \n",
    "    \n",
    "# Move Files to Downloads\n",
    "!mv yellow_tripdata_2015-01.csv Data\n",
    "!mv yellow_tripdata_2015-02.csv Data\n",
    "!mv yellow_tripdata_2015-03.csv Data\n",
    "!mv yellow_tripdata_2015-04.csv Data\n",
    "!mv yellow_tripdata_2015-05.csv Data\n",
    "!mv yellow_tripdata_2015-06.csv Data\n",
    "!mv yellow_tripdata_2015-07.csv Data\n",
    "!mv yellow_tripdata_2015-08.csv Data\n",
    "!mv yellow_tripdata_2015-09.csv Data\n",
    "!mv yellow_tripdata_2015-10.csv Data\n",
    "!mv yellow_tripdata_2015-11.csv Data\n",
    "!mv yellow_tripdata_2015-12.csv Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Download Green Taxi Data\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2015-01.csv\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2015-02.csv\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2015-03.csv\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2015-04.csv\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2015-05.csv\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2015-06.csv\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2015-07.csv\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2015-08.csv\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2015-09.csv\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2015-10.csv\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2015-11.csv\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2015-12.csv\n",
    "\n",
    "# Move data to downloads\n",
    "!mv green_tripdata_2015-01.csv Data\n",
    "!mv green_tripdata_2015-02.csv Data\n",
    "!mv green_tripdata_2015-03.csv Data\n",
    "!mv green_tripdata_2015-04.csv Data\n",
    "!mv green_tripdata_2015-05.csv Data\n",
    "!mv green_tripdata_2015-06.csv Data\n",
    "!mv green_tripdata_2015-07.csv Data\n",
    "!mv green_tripdata_2015-08.csv Data\n",
    "!mv green_tripdata_2015-09.csv Data\n",
    "!mv green_tripdata_2015-10.csv Data\n",
    "!mv green_tripdata_2015-11.csv Data\n",
    "!mv green_tripdata_2015-12.csv Data\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Download FHV Taxi Data\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-01.csv\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-02.csv\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-03.csv\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-04.csv\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-05.csv\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-06.csv\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-07.csv\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-08.csv\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-09.csv\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-10.csv\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-11.csv\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-12.csv\n",
    "    \n",
    "# Move data to downloads\n",
    "!mv fhv_tripdata_2015-01.csv Data\n",
    "!mv fhv_tripdata_2015-02.csv Data\n",
    "!mv fhv_tripdata_2015-03.csv Data\n",
    "!mv fhv_tripdata_2015-04.csv Data\n",
    "!mv fhv_tripdata_2015-05.csv Data\n",
    "!mv fhv_tripdata_2015-06.csv Data\n",
    "!mv fhv_tripdata_2015-07.csv Data\n",
    "!mv fhv_tripdata_2015-08.csv Data\n",
    "!mv fhv_tripdata_2015-09.csv Data\n",
    "!mv fhv_tripdata_2015-10.csv Data\n",
    "!mv fhv_tripdata_2015-11.csv Data\n",
    "!mv fhv_tripdata_2015-12.csv Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Download Taxi Zones Data\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/misc/taxi_zones.zip\n",
    "!mv taxi_zones.zip Data\n",
    "!mkdir Data/Taxi_Zone_Shapefile\n",
    "!unzip Data/taxi_zones.zip -d Data/Taxi_Zone_Shapefile"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Download weather data\n",
    "!wget https://raw.githubusercontent.com/andrewnell/Taxi_Demand_NYC_ADS/master/data/1106040.csv\n",
    "    \n",
    "!mv 1106040.csv Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Taxi Data Sets for Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxi Zone Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in taxi zones\n",
    "taxizones = gpd.read_file(\"Data/Taxi_Zone_Shapefile/taxi_zones.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CRS to functional one\n",
    "taxizones = taxizones.to_crs(epsg=2263)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>borough</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>POLYGON ((933100.9183527121 192536.0857092953,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>(POLYGON ((1033269.243591295 172126.0078245941...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>POLYGON ((1026308.769506665 256767.6975524619,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((992073.4667968614 203714.0760008526,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>POLYGON ((935843.3104932597 144283.3358627402,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      zone  LocationID        borough  \\\n",
       "0           Newark Airport           1            EWR   \n",
       "1              Jamaica Bay           2         Queens   \n",
       "2  Allerton/Pelham Gardens           3          Bronx   \n",
       "3            Alphabet City           4      Manhattan   \n",
       "4            Arden Heights           5  Staten Island   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((933100.9183527121 192536.0857092953,...  \n",
       "1  (POLYGON ((1033269.243591295 172126.0078245941...  \n",
       "2  POLYGON ((1026308.769506665 256767.6975524619,...  \n",
       "3  POLYGON ((992073.4667968614 203714.0760008526,...  \n",
       "4  POLYGON ((935843.3104932597 144283.3358627402,...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop redundant columns\n",
    "taxizones.drop(['OBJECTID','Shape_Leng','Shape_Area'],axis=1,inplace=True)\n",
    "taxizones.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yellow Taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# Read in Yellow Data\n",
    "YT_data01 = pd.read_csv(\"Data/yellow_tripdata_2015-01.csv\")\n",
    "print(1)\n",
    "YT_data02 = pd.read_csv(\"Data/yellow_tripdata_2015-02.csv\")\n",
    "print(2)\n",
    "YT_data03 = pd.read_csv(\"Data/yellow_tripdata_2015-03.csv\")\n",
    "print(3)\n",
    "YT_data04 = pd.read_csv(\"Data/yellow_tripdata_2015-04.csv\")\n",
    "print(4)\n",
    "YT_data05 = pd.read_csv(\"Data/yellow_tripdata_2015-05.csv\")\n",
    "print(5)\n",
    "YT_data06 = pd.read_csv(\"Data/yellow_tripdata_2015-06.csv\")\n",
    "print(6)\n",
    "YT_data07 = pd.read_csv(\"Data/yellow_tripdata_2015-07.csv\")\n",
    "print(7)\n",
    "YT_data08 = pd.read_csv(\"Data/yellow_tripdata_2015-08.csv\")\n",
    "print(8)\n",
    "YT_data09 = pd.read_csv(\"Data/yellow_tripdata_2015-09.csv\")\n",
    "print(9)\n",
    "YT_data10 = pd.read_csv(\"Data/yellow_tripdata_2015-10.csv\")\n",
    "print(10)\n",
    "YT_data11 = pd.read_csv(\"Data/yellow_tripdata_2015-11.csv\")\n",
    "print(11)\n",
    "YT_data12 = pd.read_csv(\"Data/yellow_tripdata_2015-12.csv\")\n",
    "print(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only relevant columns\n",
    "YT_data01 = YT_data01[['tpep_pickup_datetime','pickup_longitude','pickup_latitude']]\n",
    "YT_data02 = YT_data02[['tpep_pickup_datetime','pickup_longitude','pickup_latitude']]\n",
    "YT_data03 = YT_data03[['tpep_pickup_datetime','pickup_longitude','pickup_latitude']]\n",
    "YT_data04 = YT_data04[['tpep_pickup_datetime','pickup_longitude','pickup_latitude']]\n",
    "YT_data05 = YT_data05[['tpep_pickup_datetime','pickup_longitude','pickup_latitude']]\n",
    "YT_data06 = YT_data06[['tpep_pickup_datetime','pickup_longitude','pickup_latitude']]\n",
    "YT_data07 = YT_data07[['tpep_pickup_datetime','pickup_longitude','pickup_latitude']]\n",
    "YT_data08 = YT_data08[['tpep_pickup_datetime','pickup_longitude','pickup_latitude']]\n",
    "YT_data09 = YT_data09[['tpep_pickup_datetime','pickup_longitude','pickup_latitude']]\n",
    "YT_data10 = YT_data10[['tpep_pickup_datetime','pickup_longitude','pickup_latitude']]\n",
    "YT_data11 = YT_data11[['tpep_pickup_datetime','pickup_longitude','pickup_latitude']]\n",
    "YT_data12 = YT_data12[['tpep_pickup_datetime','pickup_longitude','pickup_latitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Columns for ease\n",
    "YT_data01.rename(columns={'tpep_pickup_datetime': 'pickup_date'},inplace=True)\n",
    "YT_data02.rename(columns={'tpep_pickup_datetime': 'pickup_date'},inplace=True)\n",
    "YT_data03.rename(columns={'tpep_pickup_datetime': 'pickup_date'},inplace=True)\n",
    "YT_data04.rename(columns={'tpep_pickup_datetime': 'pickup_date'},inplace=True)\n",
    "YT_data05.rename(columns={'tpep_pickup_datetime': 'pickup_date'},inplace=True)\n",
    "YT_data06.rename(columns={'tpep_pickup_datetime': 'pickup_date'},inplace=True)\n",
    "YT_data07.rename(columns={'tpep_pickup_datetime': 'pickup_date'},inplace=True)\n",
    "YT_data08.rename(columns={'tpep_pickup_datetime': 'pickup_date'},inplace=True)\n",
    "YT_data09.rename(columns={'tpep_pickup_datetime': 'pickup_date'},inplace=True)\n",
    "YT_data10.rename(columns={'tpep_pickup_datetime': 'pickup_date'},inplace=True)\n",
    "YT_data11.rename(columns={'tpep_pickup_datetime': 'pickup_date'},inplace=True)\n",
    "YT_data12.rename(columns={'tpep_pickup_datetime': 'pickup_date'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in Column for BAse Data\n",
    "YT_data01['Base'] = 'Yellow'\n",
    "YT_data02['Base'] = 'Yellow'\n",
    "YT_data03['Base'] = 'Yellow'\n",
    "YT_data04['Base'] = 'Yellow'\n",
    "YT_data05['Base'] = 'Yellow'\n",
    "YT_data06['Base'] = 'Yellow'\n",
    "YT_data07['Base'] = 'Yellow'\n",
    "YT_data08['Base'] = 'Yellow'\n",
    "YT_data09['Base'] = 'Yellow'\n",
    "YT_data10['Base'] = 'Yellow'\n",
    "YT_data11['Base'] = 'Yellow'\n",
    "YT_data12['Base'] = 'Yellow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# Convert Lat Long into point geometry\n",
    "crs = {'init':'epsg:4326'}\n",
    "\n",
    "# Convert 1\n",
    "geometry = [Point(xy) for xy in zip(YT_data01.pickup_longitude, \n",
    "                                    YT_data01.pickup_latitude)]\n",
    "YT_data01 = GeoDataFrame(YT_data01, crs=crs, geometry=geometry)\n",
    "print(1)\n",
    "\n",
    "# Convert 2\n",
    "geometry = [Point(xy) for xy in zip(YT_data02.pickup_longitude, \n",
    "                                    YT_data02.pickup_latitude)]\n",
    "YT_data02 = GeoDataFrame(YT_data02, crs=crs, geometry=geometry)\n",
    "print(2)\n",
    "\n",
    "# Convert 3\n",
    "geometry = [Point(xy) for xy in zip(YT_data03.pickup_longitude, \n",
    "                                    YT_data03.pickup_latitude)]\n",
    "YT_data03 = GeoDataFrame(YT_data03, crs=crs, geometry=geometry)\n",
    "print(3)\n",
    "\n",
    "# Convert 4\n",
    "geometry = [Point(xy) for xy in zip(YT_data04.pickup_longitude, \n",
    "                                    YT_data04.pickup_latitude)]\n",
    "YT_data04 = GeoDataFrame(YT_data04, crs=crs, geometry=geometry)\n",
    "print(4)\n",
    "\n",
    "# Convert 5\n",
    "geometry = [Point(xy) for xy in zip(YT_data05.pickup_longitude, \n",
    "                                    YT_data05.pickup_latitude)]\n",
    "YT_data05 = GeoDataFrame(YT_data05, crs=crs, geometry=geometry)\n",
    "print(5)\n",
    "\n",
    "# Convert 6\n",
    "geometry = [Point(xy) for xy in zip(YT_data06.pickup_longitude, \n",
    "                                    YT_data06.pickup_latitude)]\n",
    "YT_data06 = GeoDataFrame(YT_data06, crs=crs, geometry=geometry)\n",
    "print(6)\n",
    "\n",
    "# Convert 7\n",
    "geometry = [Point(xy) for xy in zip(YT_data07.pickup_longitude, \n",
    "                                    YT_data07.pickup_latitude)]\n",
    "YT_data07 = GeoDataFrame(YT_data07, crs=crs, geometry=geometry)\n",
    "print(7)\n",
    "\n",
    "# Convert 8\n",
    "geometry = [Point(xy) for xy in zip(YT_data08.pickup_longitude, \n",
    "                                    YT_data08.pickup_latitude)]\n",
    "YT_data08 = GeoDataFrame(YT_data08, crs=crs, geometry=geometry)\n",
    "print(8)\n",
    "\n",
    "# Convert 9\n",
    "geometry = [Point(xy) for xy in zip(YT_data09.pickup_longitude, \n",
    "                                    YT_data09.pickup_latitude)]\n",
    "YT_data09 = GeoDataFrame(YT_data09, crs=crs, geometry=geometry)\n",
    "print(9)\n",
    "\n",
    "# Convert 10\n",
    "geometry = [Point(xy) for xy in zip(YT_data10.pickup_longitude, \n",
    "                                    YT_data10.pickup_latitude)]\n",
    "YT_data10 = GeoDataFrame(YT_data10, crs=crs, geometry=geometry)\n",
    "print(10)\n",
    "\n",
    "# Convert 11\n",
    "geometry = [Point(xy) for xy in zip(YT_data11.pickup_longitude, \n",
    "                                    YT_data11.pickup_latitude)]\n",
    "YT_data11 = GeoDataFrame(YT_data11, crs=crs, geometry=geometry)\n",
    "print(11)\n",
    "\n",
    "# Convert 12\n",
    "geometry = [Point(xy) for xy in zip(YT_data12.pickup_longitude, \n",
    "                                    YT_data12.pickup_latitude)]\n",
    "YT_data12 = GeoDataFrame(YT_data12, crs=crs, geometry=geometry)\n",
    "print(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Coords out of range \n",
    "#West -74.257159 East -73.699215\n",
    "#North 40.915568 South 40.495992\n",
    "# For 1\n",
    "YT_data01 = YT_data01[~((YT_data01.pickup_longitude < -74.5) | (YT_data01.pickup_longitude > -73))]\n",
    "YT_data01 = YT_data01[~((YT_data01.pickup_latitude < 40) | (YT_data01.pickup_latitude > 41))]\n",
    "\n",
    "# For 2\n",
    "YT_data02 = YT_data02[~((YT_data02.pickup_longitude < -74.5) | (YT_data02.pickup_longitude > -73))]\n",
    "YT_data02 = YT_data02[~((YT_data02.pickup_latitude < 40) | (YT_data02.pickup_latitude > 41))]\n",
    "\n",
    "# For 3\n",
    "YT_data03 = YT_data03[~((YT_data03.pickup_longitude < -74.5) | (YT_data03.pickup_longitude > -73))]\n",
    "YT_data03 = YT_data03[~((YT_data03.pickup_latitude < 40) | (YT_data03.pickup_latitude > 41))]\n",
    "\n",
    "# For 4\n",
    "YT_data04 = YT_data04[~((YT_data04.pickup_longitude < -74.5) | (YT_data04.pickup_longitude > -73))]\n",
    "YT_data04 = YT_data04[~((YT_data04.pickup_latitude < 40) | (YT_data04.pickup_latitude > 41))]\n",
    "\n",
    "# For 5\n",
    "YT_data05 = YT_data05[~((YT_data05.pickup_longitude < -74.5) | (YT_data05.pickup_longitude > -73))]\n",
    "YT_data05 = YT_data05[~((YT_data05.pickup_latitude < 40) | (YT_data05.pickup_latitude > 41))]\n",
    "\n",
    "# For 6\n",
    "YT_data06 = YT_data06[~((YT_data06.pickup_longitude < -74.5) | (YT_data06.pickup_longitude > -73))]\n",
    "YT_data06 = YT_data06[~((YT_data06.pickup_latitude < 40) | (YT_data06.pickup_latitude > 41))]\n",
    "\n",
    "# For 7\n",
    "YT_data07 = YT_data07[~((YT_data07.pickup_longitude < -74.5) | (YT_data07.pickup_longitude > -73))]\n",
    "YT_data07 = YT_data07[~((YT_data07.pickup_latitude < 40) | (YT_data07.pickup_latitude > 41))]\n",
    "\n",
    "# For 8\n",
    "YT_data08 = YT_data08[~((YT_data08.pickup_longitude < -74.5) | (YT_data08.pickup_longitude > -73))]\n",
    "YT_data08 = YT_data08[~((YT_data08.pickup_latitude < 40) | (YT_data08.pickup_latitude > 41))]\n",
    "\n",
    "# For 9\n",
    "YT_data09 = YT_data09[~((YT_data09.pickup_longitude < -74.5) | (YT_data09.pickup_longitude > -73))]\n",
    "YT_data09 = YT_data09[~((YT_data09.pickup_latitude < 40) | (YT_data09.pickup_latitude > 41))]\n",
    "\n",
    "# For 10\n",
    "YT_data10 = YT_data10[~((YT_data10.pickup_longitude < -74.5) | (YT_data10.pickup_longitude > -73))]\n",
    "YT_data10 = YT_data10[~((YT_data10.pickup_latitude < 40) | (YT_data10.pickup_latitude > 41))]\n",
    "\n",
    "# For 11\n",
    "YT_data11 = YT_data11[~((YT_data11.pickup_longitude < -74.5) | (YT_data11.pickup_longitude > -73))]\n",
    "YT_data11 = YT_data11[~((YT_data11.pickup_latitude < 40) | (YT_data11.pickup_latitude > 41))]\n",
    "\n",
    "# For 12\n",
    "YT_data12 = YT_data12[~((YT_data12.pickup_longitude < -74.5) | (YT_data12.pickup_longitude > -73))]\n",
    "YT_data12 = YT_data12[~((YT_data12.pickup_latitude < 40) | (YT_data12.pickup_latitude > 41))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# COnvert Cooords for Spatial join\n",
    "YT_data01 =  YT_data01.to_crs(epsg=2263)\n",
    "print(1)\n",
    "YT_data02 =  YT_data02.to_crs(epsg=2263)\n",
    "print(2)\n",
    "YT_data03 =  YT_data03.to_crs(epsg=2263)\n",
    "print(3)\n",
    "YT_data04 =  YT_data04.to_crs(epsg=2263)\n",
    "print(4)\n",
    "YT_data05 =  YT_data05.to_crs(epsg=2263)\n",
    "print(5)\n",
    "YT_data06 =  YT_data06.to_crs(epsg=2263)\n",
    "print(6)\n",
    "YT_data07 =  YT_data07.to_crs(epsg=2263)\n",
    "print(7)\n",
    "YT_data08 =  YT_data08.to_crs(epsg=2263)\n",
    "print(8)\n",
    "YT_data09 =  YT_data09.to_crs(epsg=2263)\n",
    "print(9)\n",
    "YT_data10 =  YT_data10.to_crs(epsg=2263)\n",
    "print(10)\n",
    "YT_data11 =  YT_data11.to_crs(epsg=2263)\n",
    "print(11)\n",
    "YT_data12 =  YT_data12.to_crs(epsg=2263)\n",
    "print(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# Conduct Spatial Join to identify tazi zone of pickup\n",
    "YT_data01 = gpd.sjoin(YT_data01, taxizones,op='within')\n",
    "print(1)\n",
    "YT_data02 = gpd.sjoin(YT_data02, taxizones,op='within')\n",
    "print(2)\n",
    "YT_data03 = gpd.sjoin(YT_data03, taxizones,op='within')\n",
    "print(3)\n",
    "YT_data04 = gpd.sjoin(YT_data04, taxizones,op='within')\n",
    "print(4)\n",
    "YT_data05 = gpd.sjoin(YT_data05, taxizones,op='within')\n",
    "print(5)\n",
    "YT_data06 = gpd.sjoin(YT_data06, taxizones,op='within')\n",
    "print(6)\n",
    "YT_data07 = gpd.sjoin(YT_data07, taxizones,op='within')\n",
    "print(7)\n",
    "YT_data08 = gpd.sjoin(YT_data08, taxizones,op='within')\n",
    "print(8)\n",
    "YT_data09 = gpd.sjoin(YT_data09, taxizones,op='within')\n",
    "print(9)\n",
    "YT_data10 = gpd.sjoin(YT_data10, taxizones,op='within')\n",
    "print(10)\n",
    "YT_data11 = gpd.sjoin(YT_data11, taxizones,op='within')\n",
    "print(11)\n",
    "YT_data12 = gpd.sjoin(YT_data12, taxizones,op='within')\n",
    "print(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Columns\n",
    "YT_data01 = YT_data01[['pickup_date','LocationID','zone','borough','Base']]\n",
    "YT_data02 = YT_data02[['pickup_date','LocationID','zone','borough','Base']]\n",
    "YT_data03 = YT_data03[['pickup_date','LocationID','zone','borough','Base']]\n",
    "YT_data04 = YT_data04[['pickup_date','LocationID','zone','borough','Base']]\n",
    "YT_data05 = YT_data05[['pickup_date','LocationID','zone','borough','Base']]\n",
    "YT_data06 = YT_data06[['pickup_date','LocationID','zone','borough','Base']]\n",
    "YT_data07 = YT_data07[['pickup_date','LocationID','zone','borough','Base']]\n",
    "YT_data08 = YT_data08[['pickup_date','LocationID','zone','borough','Base']]\n",
    "YT_data09 = YT_data09[['pickup_date','LocationID','zone','borough','Base']]\n",
    "YT_data10 = YT_data10[['pickup_date','LocationID','zone','borough','Base']]\n",
    "YT_data11 = YT_data11[['pickup_date','LocationID','zone','borough','Base']]\n",
    "YT_data12 = YT_data12[['pickup_date','LocationID','zone','borough','Base']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Day and Hour Columns\n",
    "\n",
    "# For 1\n",
    "YT_data01.pickup_date = pd.to_datetime(YT_data01.pickup_date)\n",
    "YT_data01['date'] = YT_data01.pickup_date.dt.date\n",
    "YT_data01['hour'] = YT_data01.pickup_date.dt.hour\n",
    "\n",
    "# For 2\n",
    "YT_data02.pickup_date = pd.to_datetime(YT_data02.pickup_date)\n",
    "YT_data02['date'] = YT_data02.pickup_date.dt.date\n",
    "YT_data02['hour'] = YT_data02.pickup_date.dt.hour\n",
    "\n",
    "# For 3\n",
    "YT_data03.pickup_date = pd.to_datetime(YT_data03.pickup_date)\n",
    "YT_data03['date'] = YT_data03.pickup_date.dt.date\n",
    "YT_data03['hour'] = YT_data03.pickup_date.dt.hour\n",
    "\n",
    "# For 4\n",
    "YT_data04.pickup_date = pd.to_datetime(YT_data04.pickup_date)\n",
    "YT_data04['date'] = YT_data04.pickup_date.dt.date\n",
    "YT_data04['hour'] = YT_data04.pickup_date.dt.hour\n",
    "\n",
    "# For 5\n",
    "YT_data05.pickup_date = pd.to_datetime(YT_data05.pickup_date)\n",
    "YT_data05['date'] = YT_data05.pickup_date.dt.date\n",
    "YT_data05['hour'] = YT_data05.pickup_date.dt.hour\n",
    "\n",
    "# For 6\n",
    "YT_data06.pickup_date = pd.to_datetime(YT_data06.pickup_date)\n",
    "YT_data06['date'] = YT_data06.pickup_date.dt.date\n",
    "YT_data06['hour'] = YT_data06.pickup_date.dt.hour\n",
    "\n",
    "# For 7\n",
    "YT_data07.pickup_date = pd.to_datetime(YT_data07.pickup_date)\n",
    "YT_data07['date'] = YT_data07.pickup_date.dt.date\n",
    "YT_data07['hour'] = YT_data07.pickup_date.dt.hour\n",
    "\n",
    "# For 8\n",
    "YT_data08.pickup_date = pd.to_datetime(YT_data08.pickup_date)\n",
    "YT_data08['date'] = YT_data08.pickup_date.dt.date\n",
    "YT_data08['hour'] = YT_data08.pickup_date.dt.hour\n",
    "\n",
    "# For 9\n",
    "YT_data09.pickup_date = pd.to_datetime(YT_data09.pickup_date)\n",
    "YT_data09['date'] = YT_data09.pickup_date.dt.date\n",
    "YT_data09['hour'] = YT_data09.pickup_date.dt.hour\n",
    "\n",
    "# For 10\n",
    "YT_data10.pickup_date = pd.to_datetime(YT_data10.pickup_date)\n",
    "YT_data10['date'] = YT_data10.pickup_date.dt.date\n",
    "YT_data10['hour'] = YT_data10.pickup_date.dt.hour\n",
    "\n",
    "# For 11\n",
    "YT_data11.pickup_date = pd.to_datetime(YT_data11.pickup_date)\n",
    "YT_data11['date'] = YT_data11.pickup_date.dt.date\n",
    "YT_data11['hour'] = YT_data11.pickup_date.dt.hour\n",
    "\n",
    "# For 12\n",
    "YT_data12.pickup_date = pd.to_datetime(YT_data12.pickup_date)\n",
    "YT_data12['date'] = YT_data12.pickup_date.dt.date\n",
    "YT_data12['hour'] = YT_data12.pickup_date.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 12 month yellow taxi data set\n",
    "YT_data_12mnth = pd.concat([YT_data01,YT_data02,YT_data03,\n",
    "                            YT_data04,YT_data05,YT_data06,\n",
    "                            YT_data07,YT_data08,YT_data09,\n",
    "                            YT_data10,YT_data11,YT_data12]).reset_index()\n",
    "# Drop index column\n",
    "YT_data_12mnth.drop(['index'],axis=1,inplace=True)\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# Create 6 month yellow taxi data set\n",
    "YT_data_6mnth = pd.concat([YT_data01,YT_data02,YT_data03,\n",
    "                           YT_data04,YT_data05,YT_data06]).reset_index()\n",
    "# Drop index column\n",
    "YT_data_6mnth.drop(['index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_date</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>zone</th>\n",
       "      <th>borough</th>\n",
       "      <th>Base</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-15 19:05:39</td>\n",
       "      <td>186</td>\n",
       "      <td>Penn Station/Madison Sq West</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-10 20:33:41</td>\n",
       "      <td>186</td>\n",
       "      <td>Penn Station/Madison Sq West</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-15 19:05:42</td>\n",
       "      <td>186</td>\n",
       "      <td>Penn Station/Madison Sq West</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04 13:44:52</td>\n",
       "      <td>186</td>\n",
       "      <td>Penn Station/Madison Sq West</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-15 14:00:45</td>\n",
       "      <td>186</td>\n",
       "      <td>Penn Station/Madison Sq West</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pickup_date  LocationID                          zone    borough  \\\n",
       "0 2015-01-15 19:05:39         186  Penn Station/Madison Sq West  Manhattan   \n",
       "1 2015-01-10 20:33:41         186  Penn Station/Madison Sq West  Manhattan   \n",
       "2 2015-01-15 19:05:42         186  Penn Station/Madison Sq West  Manhattan   \n",
       "3 2015-01-04 13:44:52         186  Penn Station/Madison Sq West  Manhattan   \n",
       "4 2015-01-15 14:00:45         186  Penn Station/Madison Sq West  Manhattan   \n",
       "\n",
       "     Base        date  hour  \n",
       "0  Yellow  2015-01-15    19  \n",
       "1  Yellow  2015-01-10    20  \n",
       "2  Yellow  2015-01-15    19  \n",
       "3  Yellow  2015-01-04    13  \n",
       "4  Yellow  2015-01-15    14  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YT_data_12mnth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143674796, 7)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YT_data_12mnth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_data_12mnth.to_csv('YellowTaxi_2015.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Green Taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# Read in Green Data\n",
    "GT_data01 = pd.read_csv(\"Data/green_tripdata_2015-01.csv\")\n",
    "print(1)\n",
    "GT_data02 = pd.read_csv(\"Data/green_tripdata_2015-02.csv\")\n",
    "print(2)\n",
    "GT_data03 = pd.read_csv(\"Data/green_tripdata_2015-03.csv\")\n",
    "print(3)\n",
    "GT_data04 = pd.read_csv(\"Data/green_tripdata_2015-04.csv\")\n",
    "print(4)\n",
    "GT_data05 = pd.read_csv(\"Data/green_tripdata_2015-05.csv\")\n",
    "print(5)\n",
    "GT_data06 = pd.read_csv(\"Data/green_tripdata_2015-06.csv\")\n",
    "print(6)\n",
    "GT_data07 = pd.read_csv(\"Data/green_tripdata_2015-07.csv\")\n",
    "print(7)\n",
    "GT_data08 = pd.read_csv(\"Data/green_tripdata_2015-08.csv\")\n",
    "print(8)\n",
    "GT_data09 = pd.read_csv(\"Data/green_tripdata_2015-09.csv\")\n",
    "print(9)\n",
    "GT_data10 = pd.read_csv(\"Data/green_tripdata_2015-10.csv\")\n",
    "print(10)\n",
    "GT_data11 = pd.read_csv(\"Data/green_tripdata_2015-11.csv\")\n",
    "print(11)\n",
    "GT_data12 = pd.read_csv(\"Data/green_tripdata_2015-12.csv\")\n",
    "print(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to fix Green Taxi Columns for Jan to Jun\n",
    "\n",
    "columns = GT_data01.columns\n",
    "GT_data01 = GT_data01.reset_index()\n",
    "GT_data01 = GT_data01.drop(['Payment_type','Trip_type '], axis=1)\n",
    "GT_data01.columns = columns\n",
    "\n",
    "columns = GT_data02.columns\n",
    "GT_data02 = GT_data02.reset_index()\n",
    "GT_data02 = GT_data02.drop(['Payment_type','Trip_type '], axis=1)\n",
    "GT_data02.columns = columns\n",
    "\n",
    "columns = GT_data03.columns\n",
    "GT_data03 = GT_data03.reset_index()\n",
    "GT_data03 = GT_data03.drop(['Payment_type','Trip_type '], axis=1)\n",
    "GT_data03.columns = columns\n",
    "\n",
    "columns = GT_data04.columns\n",
    "GT_data04 = GT_data04.reset_index()\n",
    "GT_data04 = GT_data04.drop(['Payment_type','Trip_type '], axis=1)\n",
    "GT_data04.columns = columns\n",
    "\n",
    "columns = GT_data05.columns\n",
    "GT_data05 = GT_data05.reset_index()\n",
    "GT_data05 = GT_data05.drop(['Payment_type','Trip_type '], axis=1)\n",
    "GT_data05.columns = columns\n",
    "\n",
    "columns = GT_data06.columns\n",
    "GT_data06 = GT_data06.reset_index()\n",
    "GT_data06 = GT_data06.drop(['Payment_type','Trip_type '], axis=1)\n",
    "GT_data06.columns = columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only Relevant Columns\n",
    "GT_data01 = GT_data01[['lpep_pickup_datetime','Pickup_longitude','Pickup_latitude']]\n",
    "GT_data02 = GT_data02[['lpep_pickup_datetime','Pickup_longitude','Pickup_latitude']]\n",
    "GT_data03 = GT_data03[['lpep_pickup_datetime','Pickup_longitude','Pickup_latitude']]\n",
    "GT_data04 = GT_data04[['lpep_pickup_datetime','Pickup_longitude','Pickup_latitude']]\n",
    "GT_data05 = GT_data05[['lpep_pickup_datetime','Pickup_longitude','Pickup_latitude']]\n",
    "GT_data06 = GT_data06[['lpep_pickup_datetime','Pickup_longitude','Pickup_latitude']]\n",
    "GT_data07 = GT_data07[['lpep_pickup_datetime','Pickup_longitude','Pickup_latitude']]\n",
    "GT_data08 = GT_data08[['lpep_pickup_datetime','Pickup_longitude','Pickup_latitude']]\n",
    "GT_data09 = GT_data09[['lpep_pickup_datetime','Pickup_longitude','Pickup_latitude']]\n",
    "GT_data10 = GT_data10[['lpep_pickup_datetime','Pickup_longitude','Pickup_latitude']]\n",
    "GT_data11 = GT_data11[['lpep_pickup_datetime','Pickup_longitude','Pickup_latitude']]\n",
    "GT_data12 = GT_data12[['lpep_pickup_datetime','Pickup_longitude','Pickup_latitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Columns for ease\n",
    "GT_data01.rename(columns={'lpep_pickup_datetime': 'pickup_date',\n",
    "                          'Pickup_longitude':'pickup_longitude',\n",
    "                          'Pickup_latitude':'pickup_latitude'},inplace=True)\n",
    "GT_data02.rename(columns={'lpep_pickup_datetime': 'pickup_date',\n",
    "                          'Pickup_longitude':'pickup_longitude',\n",
    "                          'Pickup_latitude':'pickup_latitude'},inplace=True)\n",
    "GT_data03.rename(columns={'lpep_pickup_datetime': 'pickup_date',\n",
    "                          'Pickup_longitude':'pickup_longitude',\n",
    "                          'Pickup_latitude':'pickup_latitude'},inplace=True)\n",
    "GT_data04.rename(columns={'lpep_pickup_datetime': 'pickup_date',\n",
    "                          'Pickup_longitude':'pickup_longitude',\n",
    "                          'Pickup_latitude':'pickup_latitude'},inplace=True)\n",
    "GT_data05.rename(columns={'lpep_pickup_datetime': 'pickup_date',\n",
    "                          'Pickup_longitude':'pickup_longitude',\n",
    "                          'Pickup_latitude':'pickup_latitude'},inplace=True)\n",
    "GT_data06.rename(columns={'lpep_pickup_datetime': 'pickup_date',\n",
    "                          'Pickup_longitude':'pickup_longitude',\n",
    "                          'Pickup_latitude':'pickup_latitude'},inplace=True)\n",
    "GT_data07.rename(columns={'lpep_pickup_datetime': 'pickup_date',\n",
    "                          'Pickup_longitude':'pickup_longitude',\n",
    "                          'Pickup_latitude':'pickup_latitude'},inplace=True)\n",
    "GT_data08.rename(columns={'lpep_pickup_datetime': 'pickup_date',\n",
    "                          'Pickup_longitude':'pickup_longitude',\n",
    "                          'Pickup_latitude':'pickup_latitude'},inplace=True)\n",
    "GT_data09.rename(columns={'lpep_pickup_datetime': 'pickup_date',\n",
    "                          'Pickup_longitude':'pickup_longitude',\n",
    "                          'Pickup_latitude':'pickup_latitude'},inplace=True)\n",
    "GT_data10.rename(columns={'lpep_pickup_datetime': 'pickup_date',\n",
    "                          'Pickup_longitude':'pickup_longitude',\n",
    "                          'Pickup_latitude':'pickup_latitude'},inplace=True)\n",
    "GT_data11.rename(columns={'lpep_pickup_datetime': 'pickup_date',\n",
    "                          'Pickup_longitude':'pickup_longitude',\n",
    "                          'Pickup_latitude':'pickup_latitude'},inplace=True)\n",
    "GT_data12.rename(columns={'lpep_pickup_datetime': 'pickup_date',\n",
    "                          'Pickup_longitude':'pickup_longitude',\n",
    "                          'Pickup_latitude':'pickup_latitude'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in Column for BAse Data\n",
    "GT_data01['Base'] = 'Green'\n",
    "GT_data02['Base'] = 'Green'\n",
    "GT_data03['Base'] = 'Green'\n",
    "GT_data04['Base'] = 'Green'\n",
    "GT_data05['Base'] = 'Green'\n",
    "GT_data06['Base'] = 'Green'\n",
    "GT_data07['Base'] = 'Green'\n",
    "GT_data08['Base'] = 'Green'\n",
    "GT_data09['Base'] = 'Green'\n",
    "GT_data10['Base'] = 'Green'\n",
    "GT_data11['Base'] = 'Green'\n",
    "GT_data12['Base'] = 'Green'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# Convert Lat Long into point geometry\n",
    "crs = {'init':'epsg:4326'}\n",
    "\n",
    "# Convert 1\n",
    "geometry = [Point(xy) for xy in zip(GT_data01.pickup_longitude, \n",
    "                                    GT_data01.pickup_latitude)]\n",
    "GT_data01 = GeoDataFrame(GT_data01, crs=crs, geometry=geometry)\n",
    "print(1)\n",
    "\n",
    "# Convert 2\n",
    "geometry = [Point(xy) for xy in zip(GT_data02.pickup_longitude, \n",
    "                                    GT_data02.pickup_latitude)]\n",
    "GT_data02 = GeoDataFrame(GT_data02, crs=crs, geometry=geometry)\n",
    "print(2)\n",
    "\n",
    "# Convert 3\n",
    "geometry = [Point(xy) for xy in zip(GT_data03.pickup_longitude, \n",
    "                                    GT_data03.pickup_latitude)]\n",
    "GT_data03 = GeoDataFrame(GT_data03, crs=crs, geometry=geometry)\n",
    "print(3)\n",
    "\n",
    "# Convert 4\n",
    "geometry = [Point(xy) for xy in zip(GT_data04.pickup_longitude, \n",
    "                                    GT_data04.pickup_latitude)]\n",
    "GT_data04 = GeoDataFrame(GT_data04, crs=crs, geometry=geometry)\n",
    "print(4)\n",
    "\n",
    "# Convert 5\n",
    "geometry = [Point(xy) for xy in zip(GT_data05.pickup_longitude, \n",
    "                                    GT_data05.pickup_latitude)]\n",
    "GT_data05 = GeoDataFrame(GT_data05, crs=crs, geometry=geometry)\n",
    "print(5)\n",
    "\n",
    "# Convert 6\n",
    "geometry = [Point(xy) for xy in zip(GT_data06.pickup_longitude, \n",
    "                                    GT_data06.pickup_latitude)]\n",
    "GT_data06 = GeoDataFrame(GT_data06, crs=crs, geometry=geometry)\n",
    "print(6)\n",
    "\n",
    "# Convert 7\n",
    "geometry = [Point(xy) for xy in zip(GT_data07.pickup_longitude, \n",
    "                                    GT_data07.pickup_latitude)]\n",
    "GT_data07 = GeoDataFrame(GT_data07, crs=crs, geometry=geometry)\n",
    "print(7)\n",
    "\n",
    "# Convert 8\n",
    "geometry = [Point(xy) for xy in zip(GT_data08.pickup_longitude, \n",
    "                                    GT_data08.pickup_latitude)]\n",
    "GT_data08 = GeoDataFrame(GT_data08, crs=crs, geometry=geometry)\n",
    "print(8)\n",
    "\n",
    "# Convert 9\n",
    "geometry = [Point(xy) for xy in zip(GT_data09.pickup_longitude, \n",
    "                                    GT_data09.pickup_latitude)]\n",
    "GT_data09 = GeoDataFrame(GT_data09, crs=crs, geometry=geometry)\n",
    "print(9)\n",
    "\n",
    "# Convert 10\n",
    "geometry = [Point(xy) for xy in zip(GT_data10.pickup_longitude, \n",
    "                                    GT_data10.pickup_latitude)]\n",
    "GT_data10 = GeoDataFrame(GT_data10, crs=crs, geometry=geometry)\n",
    "print(10)\n",
    "\n",
    "# Convert 11\n",
    "geometry = [Point(xy) for xy in zip(GT_data11.pickup_longitude, \n",
    "                                    GT_data11.pickup_latitude)]\n",
    "GT_data11 = GeoDataFrame(GT_data11, crs=crs, geometry=geometry)\n",
    "print(11)\n",
    "\n",
    "# Convert 12\n",
    "geometry = [Point(xy) for xy in zip(GT_data12.pickup_longitude, \n",
    "                                    GT_data12.pickup_latitude)]\n",
    "GT_data12 = GeoDataFrame(GT_data12, crs=crs, geometry=geometry)\n",
    "print(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Coords out of range \n",
    "#West -74.257159 East -73.699215\n",
    "#North 40.915568 South 40.495992\n",
    "# For 1\n",
    "GT_data01 = GT_data01[~((GT_data01.pickup_longitude < -74.5) | (GT_data01.pickup_longitude > -73))]\n",
    "GT_data01 = GT_data01[~((GT_data01.pickup_latitude < 40) | (GT_data01.pickup_latitude > 41))]\n",
    "\n",
    "# For 2\n",
    "GT_data02 = GT_data02[~((GT_data02.pickup_longitude < -74.5) | (GT_data02.pickup_longitude > -73))]\n",
    "GT_data02 = GT_data02[~((GT_data02.pickup_latitude < 40) | (GT_data02.pickup_latitude > 41))]\n",
    "\n",
    "# For 3\n",
    "GT_data03 = GT_data03[~((GT_data03.pickup_longitude < -74.5) | (GT_data03.pickup_longitude > -73))]\n",
    "GT_data03 = GT_data03[~((GT_data03.pickup_latitude < 40) | (GT_data03.pickup_latitude > 41))]\n",
    "\n",
    "# For 4\n",
    "GT_data04 = GT_data04[~((GT_data04.pickup_longitude < -74.5) | (GT_data04.pickup_longitude > -73))]\n",
    "GT_data04 = GT_data04[~((GT_data04.pickup_latitude < 40) | (GT_data04.pickup_latitude > 41))]\n",
    "\n",
    "# For 5\n",
    "GT_data05 = GT_data05[~((GT_data05.pickup_longitude < -74.5) | (GT_data05.pickup_longitude > -73))]\n",
    "GT_data05 = GT_data05[~((GT_data05.pickup_latitude < 40) | (GT_data05.pickup_latitude > 41))]\n",
    "\n",
    "# For 6\n",
    "GT_data06 = GT_data06[~((GT_data06.pickup_longitude < -74.5) | (GT_data06.pickup_longitude > -73))]\n",
    "GT_data06 = GT_data06[~((GT_data06.pickup_latitude < 40) | (GT_data06.pickup_latitude > 41))]\n",
    "\n",
    "# For 7\n",
    "GT_data07 = GT_data07[~((GT_data07.pickup_longitude < -74.5) | (GT_data07.pickup_longitude > -73))]\n",
    "GT_data07 = GT_data07[~((GT_data07.pickup_latitude < 40) | (GT_data07.pickup_latitude > 41))]\n",
    "\n",
    "# For 8\n",
    "GT_data08 = GT_data08[~((GT_data08.pickup_longitude < -74.5) | (GT_data08.pickup_longitude > -73))]\n",
    "GT_data08 = GT_data08[~((GT_data08.pickup_latitude < 40) | (GT_data08.pickup_latitude > 41))]\n",
    "\n",
    "# For 9\n",
    "GT_data09 = GT_data09[~((GT_data09.pickup_longitude < -74.5) | (GT_data09.pickup_longitude > -73))]\n",
    "GT_data09 = GT_data09[~((GT_data09.pickup_latitude < 40) | (GT_data09.pickup_latitude > 41))]\n",
    "\n",
    "# For 10\n",
    "GT_data10 = GT_data10[~((GT_data10.pickup_longitude < -74.5) | (GT_data10.pickup_longitude > -73))]\n",
    "GT_data10 = GT_data10[~((GT_data10.pickup_latitude < 40) | (GT_data10.pickup_latitude > 41))]\n",
    "\n",
    "# For 11\n",
    "GT_data11 = GT_data11[~((GT_data11.pickup_longitude < -74.5) | (GT_data11.pickup_longitude > -73))]\n",
    "GT_data11 = GT_data11[~((GT_data11.pickup_latitude < 40) | (GT_data11.pickup_latitude > 41))]\n",
    "\n",
    "# For 12\n",
    "GT_data12 = GT_data12[~((GT_data12.pickup_longitude < -74.5) | (GT_data12.pickup_longitude > -73))]\n",
    "GT_data12 = GT_data12[~((GT_data12.pickup_latitude < 40) | (GT_data12.pickup_latitude > 41))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# COnvert Cooords for Spatial join\n",
    "GT_data01 =  GT_data01.to_crs(epsg=2263)\n",
    "print(1)\n",
    "GT_data02 =  GT_data02.to_crs(epsg=2263)\n",
    "print(2)\n",
    "GT_data03 =  GT_data03.to_crs(epsg=2263)\n",
    "print(3)\n",
    "GT_data04 =  GT_data04.to_crs(epsg=2263)\n",
    "print(4)\n",
    "GT_data05 =  GT_data05.to_crs(epsg=2263)\n",
    "print(5)\n",
    "GT_data06 =  GT_data06.to_crs(epsg=2263)\n",
    "print(6)\n",
    "GT_data07 =  GT_data07.to_crs(epsg=2263)\n",
    "print(7)\n",
    "GT_data08 =  GT_data08.to_crs(epsg=2263)\n",
    "print(8)\n",
    "GT_data09 =  GT_data09.to_crs(epsg=2263)\n",
    "print(9)\n",
    "GT_data10 =  GT_data10.to_crs(epsg=2263)\n",
    "print(10)\n",
    "GT_data11 =  GT_data11.to_crs(epsg=2263)\n",
    "print(11)\n",
    "GT_data12 =  GT_data12.to_crs(epsg=2263)\n",
    "print(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# Conduct Spatial Join to identify tazi zone of pickup\n",
    "GT_data01 = gpd.sjoin(GT_data01, taxizones,op='within')\n",
    "print(1)\n",
    "GT_data02 = gpd.sjoin(GT_data02, taxizones,op='within')\n",
    "print(2)\n",
    "GT_data03 = gpd.sjoin(GT_data03, taxizones,op='within')\n",
    "print(3)\n",
    "GT_data04 = gpd.sjoin(GT_data04, taxizones,op='within')\n",
    "print(4)\n",
    "GT_data05 = gpd.sjoin(GT_data05, taxizones,op='within')\n",
    "print(5)\n",
    "GT_data06 = gpd.sjoin(GT_data06, taxizones,op='within')\n",
    "print(6)\n",
    "GT_data07 = gpd.sjoin(GT_data07, taxizones,op='within')\n",
    "print(7)\n",
    "GT_data08 = gpd.sjoin(GT_data08, taxizones,op='within')\n",
    "print(8)\n",
    "GT_data09 = gpd.sjoin(GT_data09, taxizones,op='within')\n",
    "print(9)\n",
    "GT_data10 = gpd.sjoin(GT_data10, taxizones,op='within')\n",
    "print(10)\n",
    "GT_data11 = gpd.sjoin(GT_data11, taxizones,op='within')\n",
    "print(11)\n",
    "GT_data12 = gpd.sjoin(GT_data12, taxizones,op='within')\n",
    "print(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Columns\n",
    "GT_data01 = GT_data01[['pickup_date','LocationID','zone','borough','Base']]\n",
    "GT_data02 = GT_data02[['pickup_date','LocationID','zone','borough','Base']]\n",
    "GT_data03 = GT_data03[['pickup_date','LocationID','zone','borough','Base']]\n",
    "GT_data04 = GT_data04[['pickup_date','LocationID','zone','borough','Base']]\n",
    "GT_data05 = GT_data05[['pickup_date','LocationID','zone','borough','Base']]\n",
    "GT_data06 = GT_data06[['pickup_date','LocationID','zone','borough','Base']]\n",
    "GT_data07 = GT_data07[['pickup_date','LocationID','zone','borough','Base']]\n",
    "GT_data08 = GT_data08[['pickup_date','LocationID','zone','borough','Base']]\n",
    "GT_data09 = GT_data09[['pickup_date','LocationID','zone','borough','Base']]\n",
    "GT_data10 = GT_data10[['pickup_date','LocationID','zone','borough','Base']]\n",
    "GT_data11 = GT_data11[['pickup_date','LocationID','zone','borough','Base']]\n",
    "GT_data12 = GT_data12[['pickup_date','LocationID','zone','borough','Base']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Day and Hour Columns\n",
    "\n",
    "# For 1\n",
    "GT_data01.pickup_date = pd.to_datetime(GT_data01.pickup_date)\n",
    "GT_data01['date'] = GT_data01.pickup_date.dt.date\n",
    "GT_data01['hour'] = GT_data01.pickup_date.dt.hour\n",
    "\n",
    "# For 2\n",
    "GT_data02.pickup_date = pd.to_datetime(GT_data02.pickup_date)\n",
    "GT_data02['date'] = GT_data02.pickup_date.dt.date\n",
    "GT_data02['hour'] = GT_data02.pickup_date.dt.hour\n",
    "\n",
    "# For 3\n",
    "GT_data03.pickup_date = pd.to_datetime(GT_data03.pickup_date)\n",
    "GT_data03['date'] = GT_data03.pickup_date.dt.date\n",
    "GT_data03['hour'] = GT_data03.pickup_date.dt.hour\n",
    "\n",
    "# For 4\n",
    "GT_data04.pickup_date = pd.to_datetime(GT_data04.pickup_date)\n",
    "GT_data04['date'] = GT_data04.pickup_date.dt.date\n",
    "GT_data04['hour'] = GT_data04.pickup_date.dt.hour\n",
    "\n",
    "# For 5\n",
    "GT_data05.pickup_date = pd.to_datetime(GT_data05.pickup_date)\n",
    "GT_data05['date'] = GT_data05.pickup_date.dt.date\n",
    "GT_data05['hour'] = GT_data05.pickup_date.dt.hour\n",
    "\n",
    "# For 6\n",
    "GT_data06.pickup_date = pd.to_datetime(GT_data06.pickup_date)\n",
    "GT_data06['date'] = GT_data06.pickup_date.dt.date\n",
    "GT_data06['hour'] = GT_data06.pickup_date.dt.hour\n",
    "\n",
    "# For 7\n",
    "GT_data07.pickup_date = pd.to_datetime(GT_data07.pickup_date)\n",
    "GT_data07['date'] = GT_data07.pickup_date.dt.date\n",
    "GT_data07['hour'] = GT_data07.pickup_date.dt.hour\n",
    "\n",
    "# For 8\n",
    "GT_data08.pickup_date = pd.to_datetime(GT_data08.pickup_date)\n",
    "GT_data08['date'] = GT_data08.pickup_date.dt.date\n",
    "GT_data08['hour'] = GT_data08.pickup_date.dt.hour\n",
    "\n",
    "# For 9\n",
    "GT_data09.pickup_date = pd.to_datetime(GT_data09.pickup_date)\n",
    "GT_data09['date'] = GT_data09.pickup_date.dt.date\n",
    "GT_data09['hour'] = GT_data09.pickup_date.dt.hour\n",
    "\n",
    "# For 10\n",
    "GT_data10.pickup_date = pd.to_datetime(GT_data10.pickup_date)\n",
    "GT_data10['date'] = GT_data10.pickup_date.dt.date\n",
    "GT_data10['hour'] = GT_data10.pickup_date.dt.hour\n",
    "\n",
    "# For 11\n",
    "GT_data11.pickup_date = pd.to_datetime(GT_data11.pickup_date)\n",
    "GT_data11['date'] = GT_data11.pickup_date.dt.date\n",
    "GT_data11['hour'] = GT_data11.pickup_date.dt.hour\n",
    "\n",
    "# For 12\n",
    "GT_data12.pickup_date = pd.to_datetime(GT_data12.pickup_date)\n",
    "GT_data12['date'] = GT_data12.pickup_date.dt.date\n",
    "GT_data12['hour'] = GT_data12.pickup_date.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 12 month green taxi data set\n",
    "GT_data_12mnth = pd.concat([GT_data01,GT_data02,GT_data03,\n",
    "                            GT_data04,GT_data05,GT_data06,\n",
    "                            GT_data07,GT_data08,GT_data09,\n",
    "                            GT_data10,GT_data11,GT_data12]).reset_index()\n",
    "# Drop index column\n",
    "GT_data_12mnth.drop(['index'],axis=1,inplace=True)\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# Create 6 month green taxi data set\n",
    "GT_data_6mnth = pd.concat([GT_data01,GT_data02,GT_data03,\n",
    "                           GT_data04,GT_data05,GT_data06]).reset_index()\n",
    "# Drop index column\n",
    "GT_data_6mnth.drop(['index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_date</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>zone</th>\n",
       "      <th>borough</th>\n",
       "      <th>Base</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>457037</th>\n",
       "      <td>2015-01-10 12:00:24</td>\n",
       "      <td>1</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Green</td>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645859</th>\n",
       "      <td>2015-01-14 09:54:27</td>\n",
       "      <td>1</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Green</td>\n",
       "      <td>2015-01-14</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347520</th>\n",
       "      <td>2015-01-08 12:01:02</td>\n",
       "      <td>1</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Green</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683458</th>\n",
       "      <td>2015-01-15 06:19:29</td>\n",
       "      <td>1</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Green</td>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452086</th>\n",
       "      <td>2015-01-10 10:44:40</td>\n",
       "      <td>1</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Green</td>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pickup_date  LocationID            zone borough   Base  \\\n",
       "457037 2015-01-10 12:00:24           1  Newark Airport     EWR  Green   \n",
       "645859 2015-01-14 09:54:27           1  Newark Airport     EWR  Green   \n",
       "347520 2015-01-08 12:01:02           1  Newark Airport     EWR  Green   \n",
       "683458 2015-01-15 06:19:29           1  Newark Airport     EWR  Green   \n",
       "452086 2015-01-10 10:44:40           1  Newark Airport     EWR  Green   \n",
       "\n",
       "              date  hour  \n",
       "457037  2015-01-10    12  \n",
       "645859  2015-01-14     9  \n",
       "347520  2015-01-08    12  \n",
       "683458  2015-01-15     6  \n",
       "452086  2015-01-10    10  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GT_data01.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_date</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>zone</th>\n",
       "      <th>borough</th>\n",
       "      <th>Base</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-10 12:00:24</td>\n",
       "      <td>1</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Green</td>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-14 09:54:27</td>\n",
       "      <td>1</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Green</td>\n",
       "      <td>2015-01-14</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-08 12:01:02</td>\n",
       "      <td>1</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Green</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-15 06:19:29</td>\n",
       "      <td>1</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Green</td>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-10 10:44:40</td>\n",
       "      <td>1</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Green</td>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pickup_date  LocationID            zone borough   Base        date  \\\n",
       "0 2015-01-10 12:00:24           1  Newark Airport     EWR  Green  2015-01-10   \n",
       "1 2015-01-14 09:54:27           1  Newark Airport     EWR  Green  2015-01-14   \n",
       "2 2015-01-08 12:01:02           1  Newark Airport     EWR  Green  2015-01-08   \n",
       "3 2015-01-15 06:19:29           1  Newark Airport     EWR  Green  2015-01-15   \n",
       "4 2015-01-10 10:44:40           1  Newark Airport     EWR  Green  2015-01-10   \n",
       "\n",
       "   hour  \n",
       "0    12  \n",
       "1     9  \n",
       "2    12  \n",
       "3     6  \n",
       "4    10  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GT_data_12mnth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19190940, 7)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GT_data_12mnth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_data_12mnth.to_csv('GreenTaxi_2015.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxi Base Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Taxi Bases Lists\n",
    "TLCbasesComm = pd.read_excel(\"http://www.nyc.gov/html/tlc/downloads/excel/current_community_car_service_bases.xls\")\n",
    "TLCbasesBlack = pd.read_excel(\"http://www.nyc.gov/html/tlc/downloads/excel/current_black_car_bases.xls\")\n",
    "TLCbasesLux = pd.read_excel(\"http://www.nyc.gov/html/tlc/downloads/excel/current_luxury_limousine_bases.xls\")\n",
    "\n",
    "# Merge Taxi Bases list and drop irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Unnecessary Columns and rename ones that are inccorectly labeled\n",
    "TLCbasesComm = TLCbasesComm[['LICENSEE NUMBER', 'NAME OF LICENSEE', 'ALTERNATE NAME OF LICENSEE']]\n",
    "TLCbasesBlack = TLCbasesBlack[['LICENSEE NUMBER', 'NAME OF LICENSEE', 'ALTERNATE NAME OF LICENSEE']]\n",
    "TLCbasesLux = TLCbasesLux[['LICENSEE NUMBER', 'NAME OF LICENSEE', 'ALTERNATIVE NAME OF LICENSEE']]\n",
    "\n",
    "TLCbasesLux = TLCbasesLux.rename(columns={\"ALTERNATIVE NAME OF LICENSEE\":'ALTERNATE NAME OF LICENSEE'})\n",
    "\n",
    "# Merge Taxi Bases list and drop irrelevant columns\n",
    "TLCbases = pd.concat([TLCbasesComm,TLCbasesBlack,TLCbasesLux]).reset_index()\n",
    "TLCbases.drop(['index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LICENSEE NUMBER</th>\n",
       "      <th>NAME OF LICENSEE</th>\n",
       "      <th>ALTERNATE NAME OF LICENSEE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>B03031</td>\n",
       "      <td>ALLIANCE LIMOUSINE INC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>B03037</td>\n",
       "      <td>RIDE SOLUTION WORLDWIDE INC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>B03064</td>\n",
       "      <td>AP LUXURY LIMOUSINE INC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>B03074</td>\n",
       "      <td>BLACKBIRD WORLDWIDE CORP</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>B03082</td>\n",
       "      <td>LLUMA TRANSPORTATION CORP</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LICENSEE NUMBER             NAME OF LICENSEE ALTERNATE NAME OF LICENSEE\n",
       "862          B03031       ALLIANCE LIMOUSINE INC                        NaN\n",
       "863          B03037  RIDE SOLUTION WORLDWIDE INC                        NaN\n",
       "864          B03064      AP LUXURY LIMOUSINE INC                        NaN\n",
       "865          B03074     BLACKBIRD WORLDWIDE CORP                        NaN\n",
       "866          B03082    LLUMA TRANSPORTATION CORP                        NaN"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TLCbases.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still need o add uber base number 'B02598'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LICENSEE NUMBER</th>\n",
       "      <th>NAME OF LICENSEE</th>\n",
       "      <th>ALTERNATE NAME OF LICENSEE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B02598</td>\n",
       "      <td></td>\n",
       "      <td>uber</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LICENSEE NUMBER NAME OF LICENSEE ALTERNATE NAME OF LICENSEE\n",
       "0          B02598                                        uber"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create data point\n",
    "tempdf = pd.DataFrame([['B02598',' ','uber' ]], columns=('LICENSEE NUMBER','NAME OF LICENSEE','ALTERNATE NAME OF LICENSEE'))\n",
    "tempdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append onto dat TLC bases\n",
    "TLCbases = TLCbases.append(tempdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FHV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "#Read in FHV Data\n",
    "fhv_data01 = pd.read_csv(\"Data/fhv_tripdata_2015-01.csv\")\n",
    "print(1)\n",
    "fhv_data02 = pd.read_csv(\"Data/fhv_tripdata_2015-02.csv\")\n",
    "print(2)\n",
    "fhv_data03 = pd.read_csv(\"Data/fhv_tripdata_2015-03.csv\")\n",
    "print(3)\n",
    "fhv_data04 = pd.read_csv(\"Data/fhv_tripdata_2015-04.csv\")\n",
    "print(4)\n",
    "fhv_data05 = pd.read_csv(\"Data/fhv_tripdata_2015-05.csv\")\n",
    "print(5)\n",
    "fhv_data06 = pd.read_csv(\"Data/fhv_tripdata_2015-06.csv\")\n",
    "print(6)\n",
    "fhv_data07 = pd.read_csv(\"Data/fhv_tripdata_2015-07.csv\")\n",
    "print(7)\n",
    "fhv_data08 = pd.read_csv(\"Data/fhv_tripdata_2015-08.csv\")\n",
    "print(8)\n",
    "fhv_data09 = pd.read_csv(\"Data/fhv_tripdata_2015-09.csv\")\n",
    "print(9)\n",
    "fhv_data10 = pd.read_csv(\"Data/fhv_tripdata_2015-10.csv\")\n",
    "print(10)\n",
    "fhv_data11 = pd.read_csv(\"Data/fhv_tripdata_2015-11.csv\")\n",
    "print(11)\n",
    "fhv_data12 = pd.read_csv(\"Data/fhv_tripdata_2015-12.csv\")\n",
    "print(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with Taxi Base data set to determine actual bases\n",
    "fhv_data01 = pd.merge(fhv_data01,TLCbases,left_on='Dispatching_base_num',right_on='LICENSEE NUMBER')\n",
    "fhv_data02 = pd.merge(fhv_data02,TLCbases,left_on='Dispatching_base_num',right_on='LICENSEE NUMBER')\n",
    "fhv_data03 = pd.merge(fhv_data03,TLCbases,left_on='Dispatching_base_num',right_on='LICENSEE NUMBER')\n",
    "fhv_data04 = pd.merge(fhv_data04,TLCbases,left_on='Dispatching_base_num',right_on='LICENSEE NUMBER')\n",
    "fhv_data05 = pd.merge(fhv_data05,TLCbases,left_on='Dispatching_base_num',right_on='LICENSEE NUMBER')\n",
    "fhv_data06 = pd.merge(fhv_data06,TLCbases,left_on='Dispatching_base_num',right_on='LICENSEE NUMBER')\n",
    "fhv_data07 = pd.merge(fhv_data07,TLCbases,left_on='Dispatching_base_num',right_on='LICENSEE NUMBER')\n",
    "fhv_data08 = pd.merge(fhv_data08,TLCbases,left_on='Dispatching_base_num',right_on='LICENSEE NUMBER')\n",
    "fhv_data09 = pd.merge(fhv_data09,TLCbases,left_on='Dispatching_base_num',right_on='LICENSEE NUMBER')\n",
    "fhv_data10 = pd.merge(fhv_data10,TLCbases,left_on='Dispatching_base_num',right_on='LICENSEE NUMBER')\n",
    "fhv_data11 = pd.merge(fhv_data11,TLCbases,left_on='Dispatching_base_num',right_on='LICENSEE NUMBER')\n",
    "fhv_data12 = pd.merge(fhv_data12,TLCbases,left_on='Dispatching_base_num',right_on='LICENSEE NUMBER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Location IDs to get Borough and anme of zone\n",
    "fhv_data01 = pd.merge(fhv_data01,taxizones,left_on='locationID',right_on='LocationID')\n",
    "fhv_data02 = pd.merge(fhv_data02,taxizones,left_on='locationID',right_on='LocationID')\n",
    "fhv_data03 = pd.merge(fhv_data03,taxizones,left_on='locationID',right_on='LocationID')\n",
    "fhv_data04 = pd.merge(fhv_data04,taxizones,left_on='locationID',right_on='LocationID')\n",
    "fhv_data05 = pd.merge(fhv_data05,taxizones,left_on='locationID',right_on='LocationID')\n",
    "fhv_data06 = pd.merge(fhv_data06,taxizones,left_on='locationID',right_on='LocationID')\n",
    "fhv_data07 = pd.merge(fhv_data07,taxizones,left_on='locationID',right_on='LocationID')\n",
    "fhv_data08 = pd.merge(fhv_data08,taxizones,left_on='locationID',right_on='LocationID')\n",
    "fhv_data09 = pd.merge(fhv_data09,taxizones,left_on='locationID',right_on='LocationID')\n",
    "fhv_data10 = pd.merge(fhv_data10,taxizones,left_on='locationID',right_on='LocationID')\n",
    "fhv_data11 = pd.merge(fhv_data11,taxizones,left_on='locationID',right_on='LocationID')\n",
    "fhv_data12 = pd.merge(fhv_data12,taxizones,left_on='locationID',right_on='LocationID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns\n",
    "fhv_data01 = fhv_data01[['Pickup_date','locationID','zone','borough','ALTERNATE NAME OF LICENSEE']]\n",
    "fhv_data02 = fhv_data02[['Pickup_date','locationID','zone','borough','ALTERNATE NAME OF LICENSEE']]\n",
    "fhv_data03 = fhv_data03[['Pickup_date','locationID','zone','borough','ALTERNATE NAME OF LICENSEE']]\n",
    "fhv_data04 = fhv_data04[['Pickup_date','locationID','zone','borough','ALTERNATE NAME OF LICENSEE']]\n",
    "fhv_data05 = fhv_data05[['Pickup_date','locationID','zone','borough','ALTERNATE NAME OF LICENSEE']]\n",
    "fhv_data06 = fhv_data06[['Pickup_date','locationID','zone','borough','ALTERNATE NAME OF LICENSEE']]\n",
    "fhv_data07 = fhv_data07[['Pickup_date','locationID','zone','borough','ALTERNATE NAME OF LICENSEE']]\n",
    "fhv_data08 = fhv_data08[['Pickup_date','locationID','zone','borough','ALTERNATE NAME OF LICENSEE']]\n",
    "fhv_data09 = fhv_data09[['Pickup_date','locationID','zone','borough','ALTERNATE NAME OF LICENSEE']]\n",
    "fhv_data10 = fhv_data10[['Pickup_date','locationID','zone','borough','ALTERNATE NAME OF LICENSEE']]\n",
    "fhv_data11 = fhv_data11[['Pickup_date','locationID','zone','borough','ALTERNATE NAME OF LICENSEE']]\n",
    "fhv_data12 = fhv_data12[['Pickup_date','locationID','zone','borough','ALTERNATE NAME OF LICENSEE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for merging\n",
    "fhv_data01.rename(columns={'Pickup_date':'pickup_date',\n",
    "                           'locationID':'LocationID',\n",
    "                           'ALTERNATE NAME OF LICENSEE':'Base'},\n",
    "                  inplace=True)\n",
    "\n",
    "fhv_data02.rename(columns={'Pickup_date':'pickup_date',\n",
    "                           'locationID':'LocationID',\n",
    "                           'ALTERNATE NAME OF LICENSEE':'Base'},\n",
    "                  inplace=True)\n",
    "\n",
    "fhv_data03.rename(columns={'Pickup_date':'pickup_date',\n",
    "                           'locationID':'LocationID',\n",
    "                           'ALTERNATE NAME OF LICENSEE':'Base'},\n",
    "                  inplace=True)\n",
    "\n",
    "fhv_data04.rename(columns={'Pickup_date':'pickup_date',\n",
    "                           'locationID':'LocationID',\n",
    "                           'ALTERNATE NAME OF LICENSEE':'Base'},\n",
    "                  inplace=True)\n",
    "\n",
    "fhv_data05.rename(columns={'Pickup_date':'pickup_date',\n",
    "                           'locationID':'LocationID',\n",
    "                           'ALTERNATE NAME OF LICENSEE':'Base'},\n",
    "                  inplace=True)\n",
    "\n",
    "fhv_data06.rename(columns={'Pickup_date':'pickup_date',\n",
    "                           'locationID':'LocationID',\n",
    "                           'ALTERNATE NAME OF LICENSEE':'Base'},\n",
    "                  inplace=True)\n",
    "\n",
    "fhv_data07.rename(columns={'Pickup_date':'pickup_date',\n",
    "                           'locationID':'LocationID',\n",
    "                           'ALTERNATE NAME OF LICENSEE':'Base'},\n",
    "                  inplace=True)\n",
    "\n",
    "fhv_data08.rename(columns={'Pickup_date':'pickup_date',\n",
    "                           'locationID':'LocationID',\n",
    "                           'ALTERNATE NAME OF LICENSEE':'Base'},\n",
    "                  inplace=True)\n",
    "\n",
    "fhv_data09.rename(columns={'Pickup_date':'pickup_date',\n",
    "                           'locationID':'LocationID',\n",
    "                           'ALTERNATE NAME OF LICENSEE':'Base'},\n",
    "                  inplace=True)\n",
    "\n",
    "fhv_data10.rename(columns={'Pickup_date':'pickup_date',\n",
    "                           'locationID':'LocationID',\n",
    "                           'ALTERNATE NAME OF LICENSEE':'Base'},\n",
    "                  inplace=True)\n",
    "\n",
    "fhv_data11.rename(columns={'Pickup_date':'pickup_date',\n",
    "                           'locationID':'LocationID',\n",
    "                           'ALTERNATE NAME OF LICENSEE':'Base'},\n",
    "                  inplace=True)\n",
    "\n",
    "fhv_data12.rename(columns={'Pickup_date':'pickup_date',\n",
    "                           'locationID':'LocationID',\n",
    "                           'ALTERNATE NAME OF LICENSEE':'Base'},\n",
    "                  inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Day and Hour Columns\n",
    "\n",
    "# For 1\n",
    "fhv_data01.pickup_date = pd.to_datetime(fhv_data01.pickup_date)\n",
    "fhv_data01['date'] = fhv_data01.pickup_date.dt.date\n",
    "fhv_data01['hour'] = fhv_data01.pickup_date.dt.hour\n",
    "\n",
    "# For 2\n",
    "fhv_data02.pickup_date = pd.to_datetime(fhv_data02.pickup_date)\n",
    "fhv_data02['date'] = fhv_data02.pickup_date.dt.date\n",
    "fhv_data02['hour'] = fhv_data02.pickup_date.dt.hour\n",
    "\n",
    "# For 3\n",
    "fhv_data03.pickup_date = pd.to_datetime(fhv_data03.pickup_date)\n",
    "fhv_data03['date'] = fhv_data03.pickup_date.dt.date\n",
    "fhv_data03['hour'] = fhv_data03.pickup_date.dt.hour\n",
    "\n",
    "# For 4\n",
    "fhv_data04.pickup_date = pd.to_datetime(fhv_data04.pickup_date)\n",
    "fhv_data04['date'] = fhv_data04.pickup_date.dt.date\n",
    "fhv_data04['hour'] = fhv_data04.pickup_date.dt.hour\n",
    "\n",
    "# For 5\n",
    "fhv_data05.pickup_date = pd.to_datetime(fhv_data05.pickup_date)\n",
    "fhv_data05['date'] = fhv_data05.pickup_date.dt.date\n",
    "fhv_data05['hour'] = fhv_data05.pickup_date.dt.hour\n",
    "\n",
    "# For 6\n",
    "fhv_data06.pickup_date = pd.to_datetime(fhv_data06.pickup_date)\n",
    "fhv_data06['date'] = fhv_data06.pickup_date.dt.date\n",
    "fhv_data06['hour'] = fhv_data06.pickup_date.dt.hour\n",
    "\n",
    "# For 7\n",
    "fhv_data07.pickup_date = pd.to_datetime(fhv_data07.pickup_date)\n",
    "fhv_data07['date'] = fhv_data07.pickup_date.dt.date\n",
    "fhv_data07['hour'] = fhv_data07.pickup_date.dt.hour\n",
    "\n",
    "# For 8\n",
    "fhv_data08.pickup_date = pd.to_datetime(fhv_data08.pickup_date)\n",
    "fhv_data08['date'] = fhv_data08.pickup_date.dt.date\n",
    "fhv_data08['hour'] = fhv_data08.pickup_date.dt.hour\n",
    "\n",
    "# For 9\n",
    "fhv_data09.pickup_date = pd.to_datetime(fhv_data09.pickup_date)\n",
    "fhv_data09['date'] = fhv_data09.pickup_date.dt.date\n",
    "fhv_data09['hour'] = fhv_data09.pickup_date.dt.hour\n",
    "\n",
    "# For 10\n",
    "fhv_data10.pickup_date = pd.to_datetime(fhv_data10.pickup_date)\n",
    "fhv_data10['date'] = fhv_data10.pickup_date.dt.date\n",
    "fhv_data10['hour'] = fhv_data10.pickup_date.dt.hour\n",
    "\n",
    "# For 11\n",
    "fhv_data11.pickup_date = pd.to_datetime(fhv_data11.pickup_date)\n",
    "fhv_data11['date'] = fhv_data11.pickup_date.dt.date\n",
    "fhv_data11['hour'] = fhv_data11.pickup_date.dt.hour\n",
    "\n",
    "# For 12\n",
    "fhv_data12.pickup_date = pd.to_datetime(fhv_data12.pickup_date)\n",
    "fhv_data12['date'] = fhv_data12.pickup_date.dt.date\n",
    "fhv_data12['hour'] = fhv_data12.pickup_date.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_date</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>zone</th>\n",
       "      <th>borough</th>\n",
       "      <th>Base</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-01 00:02:00</td>\n",
       "      <td>83.0</td>\n",
       "      <td>Elmhurst/Maspeth</td>\n",
       "      <td>Queens</td>\n",
       "      <td>CAPITAL CAR SERVICE</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-01 01:13:00</td>\n",
       "      <td>83.0</td>\n",
       "      <td>Elmhurst/Maspeth</td>\n",
       "      <td>Queens</td>\n",
       "      <td>CAPITAL CAR SERVICE</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-01 07:43:00</td>\n",
       "      <td>83.0</td>\n",
       "      <td>Elmhurst/Maspeth</td>\n",
       "      <td>Queens</td>\n",
       "      <td>CAPITAL CAR SERVICE</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-01 11:20:00</td>\n",
       "      <td>83.0</td>\n",
       "      <td>Elmhurst/Maspeth</td>\n",
       "      <td>Queens</td>\n",
       "      <td>CAPITAL CAR SERVICE</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-12-01 11:44:00</td>\n",
       "      <td>83.0</td>\n",
       "      <td>Elmhurst/Maspeth</td>\n",
       "      <td>Queens</td>\n",
       "      <td>CAPITAL CAR SERVICE</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pickup_date  LocationID              zone borough  \\\n",
       "0 2015-12-01 00:02:00        83.0  Elmhurst/Maspeth  Queens   \n",
       "1 2015-12-01 01:13:00        83.0  Elmhurst/Maspeth  Queens   \n",
       "2 2015-12-01 07:43:00        83.0  Elmhurst/Maspeth  Queens   \n",
       "3 2015-12-01 11:20:00        83.0  Elmhurst/Maspeth  Queens   \n",
       "4 2015-12-01 11:44:00        83.0  Elmhurst/Maspeth  Queens   \n",
       "\n",
       "                  Base        date  hour  \n",
       "0  CAPITAL CAR SERVICE  2015-12-01     0  \n",
       "1  CAPITAL CAR SERVICE  2015-12-01     1  \n",
       "2  CAPITAL CAR SERVICE  2015-12-01     7  \n",
       "3  CAPITAL CAR SERVICE  2015-12-01    11  \n",
       "4  CAPITAL CAR SERVICE  2015-12-01    11  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fhv_data12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 12 month fhv taxi data set\n",
    "fhv_data_12mnth = pd.concat([fhv_data01,fhv_data02,fhv_data03,\n",
    "                             fhv_data04,fhv_data05,fhv_data06,\n",
    "                             fhv_data07,fhv_data08,fhv_data09,\n",
    "                             fhv_data10,fhv_data11,fhv_data12]).reset_index()\n",
    "# Drop index column\n",
    "fhv_data_12mnth.drop(['index'],axis=1,inplace=True)\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# Create 6 month fhv taxi data set\n",
    "fhv_data_6mnth = pd.concat([fhv_data01,fhv_data02,fhv_data03,\n",
    "                            fhv_data04,fhv_data05,fhv_data06]).reset_index()\n",
    "# Drop index column\n",
    "fhv_data_6mnth.drop(['index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_date</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>zone</th>\n",
       "      <th>borough</th>\n",
       "      <th>Base</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01 01:05:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Chinatown</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-06 07:15:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Chinatown</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06 23:45:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Chinatown</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-15 23:45:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Chinatown</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-29 23:45:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Chinatown</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-29</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pickup_date  LocationID       zone    borough Base        date  hour\n",
       "0 2015-01-01 01:05:00        45.0  Chinatown  Manhattan  NaN  2015-01-01     1\n",
       "1 2015-01-06 07:15:00        45.0  Chinatown  Manhattan  NaN  2015-01-06     7\n",
       "2 2015-01-06 23:45:00        45.0  Chinatown  Manhattan  NaN  2015-01-06    23\n",
       "3 2015-01-15 23:45:00        45.0  Chinatown  Manhattan  NaN  2015-01-15    23\n",
       "4 2015-01-29 23:45:00        45.0  Chinatown  Manhattan  NaN  2015-01-29    23"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fhv_data_12mnth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45070796, 7)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fhv_data_12mnth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhv_data_12mnth.to_csv('FHVTaxi_2015.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge all taxi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data sets\n",
    "taxi_01 = pd.concat([YT_data01,GT_data01,fhv_data01]).reset_index()\n",
    "taxi_6mnth = pd.concat([YT_data_6mnth,GT_data_6mnth,fhv_data_6mnth]).reset_index()\n",
    "taxi_12mnth = pd.concat([YT_data_12mnth,GT_data_12mnth,fhv_data_12mnth]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Data\n",
    "taxi_01.to_csv('Taxi_201501.csv')\n",
    "#taxi_6mnth.to_csv('Taxi_201501-201506.csv')\n",
    "taxi_12mnth.to_csv('Taxi_2015.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduce Weather Data and merge with data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "weather_data = pd.read_csv(\"Data/1106040.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>STATION_NAME</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>REPORTTPYE</th>\n",
       "      <th>HOURLYSKYCONDITIONS</th>\n",
       "      <th>HOURLYVISIBILITY</th>\n",
       "      <th>HOURLYPRSENTWEATHERTYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>MonthlyMaxSeaLevelPressureTime</th>\n",
       "      <th>MonthlyMinSeaLevelPressureValue</th>\n",
       "      <th>MonthlyMinSeaLevelPressureDate</th>\n",
       "      <th>MonthlyMinSeaLevelPressureTime</th>\n",
       "      <th>MonthlyTotalHeatingDegreeDays</th>\n",
       "      <th>MonthlyTotalCoolingDegreeDays</th>\n",
       "      <th>MonthlyDeptFromNormalHeatingDD</th>\n",
       "      <th>MonthlyDeptFromNormalCoolingDD</th>\n",
       "      <th>MonthlyTotalSeasonToDateHeatingDD</th>\n",
       "      <th>MonthlyTotalSeasonToDateCoolingDD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WBAN:94728</td>\n",
       "      <td>NY CITY CENTRAL PARK NY US</td>\n",
       "      <td>42.7</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>4/1/2014 0:51</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>CLR:00</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WBAN:94728</td>\n",
       "      <td>NY CITY CENTRAL PARK NY US</td>\n",
       "      <td>42.7</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>4/1/2014 1:51</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>CLR:00</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WBAN:94728</td>\n",
       "      <td>NY CITY CENTRAL PARK NY US</td>\n",
       "      <td>42.7</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>4/1/2014 2:51</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>CLR:00</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WBAN:94728</td>\n",
       "      <td>NY CITY CENTRAL PARK NY US</td>\n",
       "      <td>42.7</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>4/1/2014 3:51</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>CLR:00</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WBAN:94728</td>\n",
       "      <td>NY CITY CENTRAL PARK NY US</td>\n",
       "      <td>42.7</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>4/1/2014 4:51</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>CLR:00</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      STATION                STATION_NAME  ELEVATION  LATITUDE  LONGITUDE  \\\n",
       "0  WBAN:94728  NY CITY CENTRAL PARK NY US       42.7  40.77898  -73.96925   \n",
       "1  WBAN:94728  NY CITY CENTRAL PARK NY US       42.7  40.77898  -73.96925   \n",
       "2  WBAN:94728  NY CITY CENTRAL PARK NY US       42.7  40.77898  -73.96925   \n",
       "3  WBAN:94728  NY CITY CENTRAL PARK NY US       42.7  40.77898  -73.96925   \n",
       "4  WBAN:94728  NY CITY CENTRAL PARK NY US       42.7  40.77898  -73.96925   \n",
       "\n",
       "            DATE REPORTTPYE HOURLYSKYCONDITIONS HOURLYVISIBILITY  \\\n",
       "0  4/1/2014 0:51      FM-15              CLR:00               10   \n",
       "1  4/1/2014 1:51      FM-15              CLR:00               10   \n",
       "2  4/1/2014 2:51      FM-15              CLR:00               10   \n",
       "3  4/1/2014 3:51      FM-15              CLR:00               10   \n",
       "4  4/1/2014 4:51      FM-15              CLR:00               10   \n",
       "\n",
       "  HOURLYPRSENTWEATHERTYPE                ...                  \\\n",
       "0                     NaN                ...                   \n",
       "1                     NaN                ...                   \n",
       "2                     NaN                ...                   \n",
       "3                     NaN                ...                   \n",
       "4                     NaN                ...                   \n",
       "\n",
       "   MonthlyMaxSeaLevelPressureTime  MonthlyMinSeaLevelPressureValue  \\\n",
       "0                           -9999                              NaN   \n",
       "1                           -9999                              NaN   \n",
       "2                           -9999                              NaN   \n",
       "3                           -9999                              NaN   \n",
       "4                           -9999                              NaN   \n",
       "\n",
       "   MonthlyMinSeaLevelPressureDate  MonthlyMinSeaLevelPressureTime  \\\n",
       "0                           -9999                           -9999   \n",
       "1                           -9999                           -9999   \n",
       "2                           -9999                           -9999   \n",
       "3                           -9999                           -9999   \n",
       "4                           -9999                           -9999   \n",
       "\n",
       "  MonthlyTotalHeatingDegreeDays MonthlyTotalCoolingDegreeDays  \\\n",
       "0                           NaN                           NaN   \n",
       "1                           NaN                           NaN   \n",
       "2                           NaN                           NaN   \n",
       "3                           NaN                           NaN   \n",
       "4                           NaN                           NaN   \n",
       "\n",
       "   MonthlyDeptFromNormalHeatingDD  MonthlyDeptFromNormalCoolingDD  \\\n",
       "0                             NaN                             NaN   \n",
       "1                             NaN                             NaN   \n",
       "2                             NaN                             NaN   \n",
       "3                             NaN                             NaN   \n",
       "4                             NaN                             NaN   \n",
       "\n",
       "  MonthlyTotalSeasonToDateHeatingDD  MonthlyTotalSeasonToDateCoolingDD  \n",
       "0                               NaN                                NaN  \n",
       "1                               NaN                                NaN  \n",
       "2                               NaN                                NaN  \n",
       "3                               NaN                                NaN  \n",
       "4                               NaN                                NaN  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'STATION', u'STATION_NAME', u'ELEVATION', u'LATITUDE', u'LONGITUDE',\n",
       "       u'DATE', u'REPORTTPYE', u'HOURLYSKYCONDITIONS', u'HOURLYVISIBILITY',\n",
       "       u'HOURLYPRSENTWEATHERTYPE', u'HOURLYDRYBULBTEMPF',\n",
       "       u'HOURLYDRYBULBTEMPC', u'HOURLYWETBULBTEMPF', u'HOURLYWETBULBTEMPC',\n",
       "       u'HOURLYDewPointTempF', u'HOURLYDewPointTempC',\n",
       "       u'HOURLYRelativeHumidity', u'HOURLYWindSpeed', u'HOURLYWindDirection',\n",
       "       u'HOURLYWindGustSpeed', u'HOURLYStationPressure',\n",
       "       u'HOURLYPressureTendency', u'HOURLYPressureChange',\n",
       "       u'HOURLYSeaLevelPressure', u'HOURLYPrecip', u'HOURLYAltimeterSetting',\n",
       "       u'DAILYMaximumDryBulbTemp', u'DAILYMinimumDryBulbTemp',\n",
       "       u'DAILYAverageDryBulbTemp', u'DAILYDeptFromNormalAverageTemp',\n",
       "       u'DAILYAverageRelativeHumidity', u'DAILYAverageDewPointTemp',\n",
       "       u'DAILYAverageWetBulbTemp', u'DAILYHeatingDegreeDays',\n",
       "       u'DAILYCoolingDegreeDays', u'DAILYSunrise', u'DAILYSunset',\n",
       "       u'DAILYWeather', u'DAILYPrecip', u'DAILYSnowfall', u'DAILYSnowDepth',\n",
       "       u'DAILYAverageStationPressure', u'DAILYAverageSeaLevelPressure',\n",
       "       u'DAILYAverageWindSpeed', u'DAILYPeakWindSpeed', u'PeakWindDirection',\n",
       "       u'DAILYSustainedWindSpeed', u'DAILYSustainedWindDirection',\n",
       "       u'MonthlyMaximumTemp', u'MonthlyMinimumTemp', u'MonthlyMeanTemp',\n",
       "       u'MonthlyAverageRH', u'MonthlyDewpointTemp', u'MonthlyWetBulbTemp',\n",
       "       u'MonthlyAvgHeatingDegreeDays', u'MonthlyAvgCoolingDegreeDays',\n",
       "       u'MonthlyStationPressure', u'MonthlySeaLevelPressure',\n",
       "       u'MonthlyAverageWindSpeed', u'MonthlyTotalSnowfall',\n",
       "       u'MonthlyDeptFromNormalMaximumTemp',\n",
       "       u'MonthlyDeptFromNormalMinimumTemp',\n",
       "       u'MonthlyDeptFromNormalAverageTemp', u'MonthlyDeptFromNormalPrecip',\n",
       "       u'MonthlyTotalLiquidPrecip', u'MonthlyGreatestPrecip',\n",
       "       u'MonthlyGreatestPrecipDate', u'MonthlyGreatestSnowfall',\n",
       "       u'MonthlyGreatestSnowfallDate', u'MonthlyGreatestSnowDepth',\n",
       "       u'MonthlyGreatestSnowDepthDate', u'MonthlyDaysWithGT90Temp',\n",
       "       u'MonthlyDaysWithLT32Temp', u'MonthlyDaysWithGT32Temp',\n",
       "       u'MonthlyDaysWithLT0Temp', u'MonthlyDaysWithGT001Precip',\n",
       "       u'MonthlyDaysWithGT010Precip', u'MonthlyDaysWithGT1Snow',\n",
       "       u'MonthlyMaxSeaLevelPressureValue', u'MonthlyMaxSeaLevelPressureDate',\n",
       "       u'MonthlyMaxSeaLevelPressureTime', u'MonthlyMinSeaLevelPressureValue',\n",
       "       u'MonthlyMinSeaLevelPressureDate', u'MonthlyMinSeaLevelPressureTime',\n",
       "       u'MonthlyTotalHeatingDegreeDays', u'MonthlyTotalCoolingDegreeDays',\n",
       "       u'MonthlyDeptFromNormalHeatingDD', u'MonthlyDeptFromNormalCoolingDD',\n",
       "       u'MonthlyTotalSeasonToDateHeatingDD',\n",
       "       u'MonthlyTotalSeasonToDateCoolingDD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Remove irrelevant columns\n",
    "weather_data.drop(['STATION','STATION_NAME','ELEVATION','LATITUDE','LONGITUDE',\n",
    "                   'REPORTTPYE','HOURLYPRSENTWEATHERTYPE',\n",
    "                   'HOURLYDRYBULBTEMPC','HOURLYWETBULBTEMPC',\n",
    "                   'HOURLYDewPointTempF','HOURLYDewPointTempC',\n",
    "                   'HOURLYRelativeHumidity','HOURLYWindDirection',\n",
    "                   'HOURLYStationPressure','HOURLYPressureTendency',\n",
    "                   'HOURLYPressureChange','HOURLYSeaLevelPressure',\n",
    "                   'HOURLYAltimeterSetting','DAILYMaximumDryBulbTemp',\n",
    "                   'DAILYMinimumDryBulbTemp','DAILYAverageDryBulbTemp',\n",
    "                   'DAILYDeptFromNormalAverageTemp',\n",
    "                   'DAILYAverageRelativeHumidity',\n",
    "                   'DAILYAverageDewPointTemp','DAILYAverageWetBulbTemp',\n",
    "                   'DAILYHeatingDegreeDays','DAILYCoolingDegreeDays',\n",
    "                   'DAILYSunrise','DAILYSunset','DAILYWeather',\n",
    "                   'DAILYPrecip','DAILYAverageStationPressure',\n",
    "                   'DAILYAverageSeaLevelPressure','DAILYAverageWindSpeed',\n",
    "                   'DAILYPeakWindSpeed','PeakWindDirection',\n",
    "                   'DAILYSustainedWindSpeed','DAILYSustainedWindDirection',\n",
    "                   'MonthlyMaximumTemp','MonthlyMinimumTemp','MonthlyMeanTemp',\n",
    "                   'MonthlyAverageRH', 'MonthlyDewpointTemp',\n",
    "                   'MonthlyWetBulbTemp','MonthlyAvgHeatingDegreeDays',\n",
    "                   'MonthlyAvgCoolingDegreeDays','MonthlyStationPressure',\n",
    "                   'MonthlySeaLevelPressure','MonthlyAverageWindSpeed',\n",
    "                   'MonthlyTotalSnowfall','MonthlyDeptFromNormalMaximumTemp',\n",
    "                   'MonthlyDeptFromNormalMinimumTemp',\n",
    "                   'MonthlyDeptFromNormalAverageTemp',\n",
    "                   'MonthlyDeptFromNormalPrecip','MonthlyTotalLiquidPrecip',\n",
    "                   'MonthlyGreatestPrecip','MonthlyGreatestPrecipDate',\n",
    "                   'MonthlyGreatestSnowfall','MonthlyGreatestSnowfallDate',\n",
    "                   'MonthlyGreatestSnowDepth','MonthlyGreatestSnowDepthDate',\n",
    "                   'MonthlyDaysWithGT90Temp','MonthlyDaysWithLT32Temp',\n",
    "                   'MonthlyDaysWithGT32Temp','MonthlyDaysWithLT0Temp',\n",
    "                   'MonthlyDaysWithGT001Precip','MonthlyDaysWithGT010Precip',\n",
    "                   'MonthlyDaysWithGT1Snow','MonthlyMaxSeaLevelPressureValue',\n",
    "                   'MonthlyMaxSeaLevelPressureDate',\n",
    "                   'MonthlyMaxSeaLevelPressureTime',\n",
    "                   'MonthlyMinSeaLevelPressureValue',\n",
    "                   'MonthlyMinSeaLevelPressureDate',\n",
    "                   'MonthlyMinSeaLevelPressureTime',\n",
    "                   'MonthlyTotalHeatingDegreeDays',\n",
    "                   'MonthlyTotalCoolingDegreeDays',\n",
    "                   'MonthlyDeptFromNormalHeatingDD',\n",
    "                   'MonthlyDeptFromNormalCoolingDD',\n",
    "                   'MonthlyTotalSeasonToDateHeatingDD',\n",
    "                   'MonthlyTotalSeasonToDateCoolingDD'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>HOURLYSKYCONDITIONS</th>\n",
       "      <th>HOURLYVISIBILITY</th>\n",
       "      <th>HOURLYDRYBULBTEMPF</th>\n",
       "      <th>HOURLYWETBULBTEMPF</th>\n",
       "      <th>HOURLYWindSpeed</th>\n",
       "      <th>HOURLYWindGustSpeed</th>\n",
       "      <th>HOURLYPrecip</th>\n",
       "      <th>DAILYSnowfall</th>\n",
       "      <th>DAILYSnowDepth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/1/2014 0:51</td>\n",
       "      <td>CLR:00</td>\n",
       "      <td>10</td>\n",
       "      <td>41.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/1/2014 1:51</td>\n",
       "      <td>CLR:00</td>\n",
       "      <td>10</td>\n",
       "      <td>41.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/1/2014 2:51</td>\n",
       "      <td>CLR:00</td>\n",
       "      <td>10</td>\n",
       "      <td>40.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/1/2014 3:51</td>\n",
       "      <td>CLR:00</td>\n",
       "      <td>10</td>\n",
       "      <td>40.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/1/2014 4:51</td>\n",
       "      <td>CLR:00</td>\n",
       "      <td>10</td>\n",
       "      <td>39.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            DATE HOURLYSKYCONDITIONS HOURLYVISIBILITY  HOURLYDRYBULBTEMPF  \\\n",
       "0  4/1/2014 0:51              CLR:00               10                41.0   \n",
       "1  4/1/2014 1:51              CLR:00               10                41.0   \n",
       "2  4/1/2014 2:51              CLR:00               10                40.0   \n",
       "3  4/1/2014 3:51              CLR:00               10                40.0   \n",
       "4  4/1/2014 4:51              CLR:00               10                39.0   \n",
       "\n",
       "   HOURLYWETBULBTEMPF  HOURLYWindSpeed  HOURLYWindGustSpeed HOURLYPrecip  \\\n",
       "0                35.0              6.0                  NaN            0   \n",
       "1                35.0              9.0                  NaN            0   \n",
       "2                34.0              9.0                  NaN            0   \n",
       "3                34.0              8.0                 16.0            0   \n",
       "4                34.0              3.0                  NaN            0   \n",
       "\n",
       "  DAILYSnowfall DAILYSnowDepth  \n",
       "0           NaN            NaN  \n",
       "1           NaN            NaN  \n",
       "2           NaN            NaN  \n",
       "3           NaN            NaN  \n",
       "4           NaN            NaN  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE                    object\n",
       "HOURLYSKYCONDITIONS     object\n",
       "HOURLYVISIBILITY        object\n",
       "HOURLYDRYBULBTEMPF     float64\n",
       "HOURLYWETBULBTEMPF     float64\n",
       "HOURLYWindSpeed        float64\n",
       "HOURLYWindGustSpeed    float64\n",
       "HOURLYPrecip            object\n",
       "DAILYSnowfall           object\n",
       "DAILYSnowDepth          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date into datetime for merging\n",
    "weather_data.DATE = pd.to_datetime(weather_data.DATE)\n",
    "weather_data['date'] = weather_data.DATE.dt.date\n",
    "weather_data['hour'] = weather_data.DATE.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.  ,  0.01,  0.04,  0.02,   nan,  0.1 ,  0.08,  0.03,  0.07,\n",
       "        0.11,  0.06,  0.05,  0.15,  0.16,  0.09,  0.12,  0.13,  0.17,\n",
       "        0.24,  0.3 ,  0.18,  0.2 ,  0.25,  0.23,  0.22,  0.14,  0.28,\n",
       "        0.19,  0.27,  0.34,  0.35,  0.41,  0.26,  0.44,  0.56,  0.32,\n",
       "        0.53,  0.33,  0.21,  1.  ,  0.42,  0.43,  0.4 ,  0.46,  0.37,\n",
       "        0.36,  0.48,  0.69,  1.03,  0.39,  0.38,  0.59,  0.91,  0.5 ,\n",
       "        0.31,  0.78,  0.52,  0.51,  0.29,  0.97])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data.HOURLYPrecip.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data cleaning\n",
    "weather_data.dropna(subset=['HOURLYDRYBULBTEMPF'],inplace=True)\n",
    "weather_data.HOURLYPrecip = weather_data.HOURLYPrecip.replace(\"T\",0)\n",
    "weather_data.HOURLYPrecip = weather_data.HOURLYPrecip.replace(\"s\",' ', regex=True)\n",
    "weather_data.HOURLYPrecip = weather_data.HOURLYPrecip.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with data sets for 1 month\n",
    "taxi_01weather = taxi_01.merge(weather_data,on=['date','hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with data sets for year\n",
    "taxi_12mnthweather = taxi_12mnth.merge(weather_data,on=['date','hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irellevant columns\n",
    "taxi_01weather.drop(['index','DATE'],axis=1,inplace=True)\n",
    "taxi_12mnthweather.drop(['index','DATE'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_date</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>zone</th>\n",
       "      <th>borough</th>\n",
       "      <th>Base</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>HOURLYSKYCONDITIONS</th>\n",
       "      <th>HOURLYVISIBILITY</th>\n",
       "      <th>HOURLYDRYBULBTEMPF</th>\n",
       "      <th>HOURLYWETBULBTEMPF</th>\n",
       "      <th>HOURLYWindSpeed</th>\n",
       "      <th>HOURLYWindGustSpeed</th>\n",
       "      <th>HOURLYPrecip</th>\n",
       "      <th>DAILYSnowfall</th>\n",
       "      <th>DAILYSnowDepth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-15 19:05:39</td>\n",
       "      <td>186.0</td>\n",
       "      <td>Penn Station/Madison Sq West</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>19</td>\n",
       "      <td>CLR:00</td>\n",
       "      <td>10</td>\n",
       "      <td>33.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-15 19:05:42</td>\n",
       "      <td>186.0</td>\n",
       "      <td>Penn Station/Madison Sq West</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>19</td>\n",
       "      <td>CLR:00</td>\n",
       "      <td>10</td>\n",
       "      <td>33.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-15 19:13:05</td>\n",
       "      <td>186.0</td>\n",
       "      <td>Penn Station/Madison Sq West</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>19</td>\n",
       "      <td>CLR:00</td>\n",
       "      <td>10</td>\n",
       "      <td>33.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-15 19:27:12</td>\n",
       "      <td>186.0</td>\n",
       "      <td>Penn Station/Madison Sq West</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>19</td>\n",
       "      <td>CLR:00</td>\n",
       "      <td>10</td>\n",
       "      <td>33.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-15 19:19:13</td>\n",
       "      <td>186.0</td>\n",
       "      <td>Penn Station/Madison Sq West</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>19</td>\n",
       "      <td>CLR:00</td>\n",
       "      <td>10</td>\n",
       "      <td>33.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pickup_date  LocationID                          zone    borough  \\\n",
       "0 2015-01-15 19:05:39       186.0  Penn Station/Madison Sq West  Manhattan   \n",
       "1 2015-01-15 19:05:42       186.0  Penn Station/Madison Sq West  Manhattan   \n",
       "2 2015-01-15 19:13:05       186.0  Penn Station/Madison Sq West  Manhattan   \n",
       "3 2015-01-15 19:27:12       186.0  Penn Station/Madison Sq West  Manhattan   \n",
       "4 2015-01-15 19:19:13       186.0  Penn Station/Madison Sq West  Manhattan   \n",
       "\n",
       "     Base        date  hour HOURLYSKYCONDITIONS HOURLYVISIBILITY  \\\n",
       "0  Yellow  2015-01-15    19              CLR:00               10   \n",
       "1  Yellow  2015-01-15    19              CLR:00               10   \n",
       "2  Yellow  2015-01-15    19              CLR:00               10   \n",
       "3  Yellow  2015-01-15    19              CLR:00               10   \n",
       "4  Yellow  2015-01-15    19              CLR:00               10   \n",
       "\n",
       "   HOURLYDRYBULBTEMPF  HOURLYWETBULBTEMPF  HOURLYWindSpeed  \\\n",
       "0                33.0                27.0              9.0   \n",
       "1                33.0                27.0              9.0   \n",
       "2                33.0                27.0              9.0   \n",
       "3                33.0                27.0              9.0   \n",
       "4                33.0                27.0              9.0   \n",
       "\n",
       "   HOURLYWindGustSpeed  HOURLYPrecip DAILYSnowfall DAILYSnowDepth  \n",
       "0                 20.0           0.0           NaN            NaN  \n",
       "1                 20.0           0.0           NaN            NaN  \n",
       "2                 20.0           0.0           NaN            NaN  \n",
       "3                 20.0           0.0           NaN            NaN  \n",
       "4                 20.0           0.0           NaN            NaN  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_12mnthweather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Grouped data set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>COUNTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  hour  LocationID  COUNTS\n",
       "0  2015-01-01     0         3.0       5\n",
       "1  2015-01-01     0         4.0     237\n",
       "2  2015-01-01     0         7.0     501\n",
       "3  2015-01-01     0         8.0       1\n",
       "4  2015-01-01     0         9.0       3"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 month data group\n",
    "taxi_01group = taxi_01weather.groupby(('date','hour','LocationID'))['pickup_date'].count().reset_index()\n",
    "taxi_01group.rename(columns={'pickup_date':'COUNTS'},inplace=True)\n",
    "taxi_01group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>COUNTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  hour  LocationID  COUNTS\n",
       "0  2015-01-01     0         3.0       5\n",
       "1  2015-01-01     0         4.0     237\n",
       "2  2015-01-01     0         7.0     501\n",
       "3  2015-01-01     0         8.0       1\n",
       "4  2015-01-01     0         9.0       3"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12 month data group\n",
    "taxi_12mnthgroup = taxi_12mnthweather.groupby(('date','hour','LocationID'))['pickup_date'].count().reset_index()\n",
    "taxi_12mnthgroup.rename(columns={'pickup_date':'COUNTS'},inplace=True)\n",
    "taxi_12mnthgroup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Data\n",
    "taxi_01weather.to_csv('Taxi_201501_.csv')\n",
    "#taxi_6mnth.to_csv('Taxi_201501-201506.csv')\n",
    "taxi_12mnthweather.to_csv('Taxi_2015_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Group Data\n",
    "taxi_01group.to_csv('Taxi_201501_grouped.csv')\n",
    "taxi_12mnthgroup.to_csv('Taxi_2015_grouped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PUI2016_Python2",
   "language": "python",
   "name": "pui2016_python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
